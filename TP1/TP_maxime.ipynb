{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f162cb4f",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7c7b7c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=10000,suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0262dac4",
   "metadata": {},
   "source": [
    "## Données\n",
    "Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "284c32b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (150, 4)\n",
      "y shape: (150,)\n",
      "[[5.1 3.5 1.4 0.2]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "def load_data(path):\n",
    "    data = pd.read_csv('data/' + path, header=None, sep='\\t')\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "    print(\"X shape:\", X.shape)\n",
    "    print(\"y shape:\", y.shape)\n",
    "    return X, y\n",
    "\n",
    "X, y = load_data('iris.txt')\n",
    "\n",
    "# afficher la premiere ligne de X et y\n",
    "print(X[:1])\n",
    "print(y[:1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debbc15e",
   "metadata": {},
   "source": [
    "Découpage de la base d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3ed3fe76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (100, 4)\n",
      "X_test shape: (50, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42, stratify=y)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475873c5",
   "metadata": {},
   "source": [
    "## Perceptron Multi-classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7fbc1107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "perceptron = Perceptron(max_iter=1000, eta0=0.1, random_state=42)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "y_pred = perceptron.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6e3655cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion:\n",
      "[[15  1  0]\n",
      " [ 0  8  9]\n",
      " [ 0  0 17]]\n",
      "\n",
      "Accuracy globale: 0.8000\n",
      "\n",
      "Précision par classe:\n",
      "  Classe 1: 1.0000\n",
      "  Classe 2: 0.8889\n",
      "  Classe 3: 0.6538\n",
      "\n",
      "Rappel par classe:\n",
      "  Classe 1: 0.9375\n",
      "  Classe 2: 0.4706\n",
      "  Classe 3: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "\n",
    "def display_metrics(y_test, y_pred):\n",
    "    # Matrice de confusion\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Matrice de confusion:\")\n",
    "    print(cm)\n",
    "\n",
    "    # Accuracy globale\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\nAccuracy globale: {accuracy:.4f}\")\n",
    "\n",
    "    # Précision pour chaque classe\n",
    "    precision = precision_score(y_test, y_pred, average=None, zero_division=0)\n",
    "    print(\"\\nPrécision par classe:\")\n",
    "    for i, p in enumerate(precision):\n",
    "        print(f\"  Classe {i+1}: {p:.4f}\")\n",
    "\n",
    "    # Rappel pour chaque classe\n",
    "    recall = recall_score(y_test, y_pred, average=None, zero_division=0)\n",
    "    print(\"\\nRappel par classe:\")\n",
    "    for i, r in enumerate(recall):\n",
    "        print(f\"  Classe {i+1}: {r:.4f}\")\n",
    "\n",
    "display_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eecb41",
   "metadata": {},
   "source": [
    "## Perceptron Multi Couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d02c16c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion:\n",
      "[[16  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  0 17]]\n",
      "\n",
      "Accuracy globale: 0.9800\n",
      "\n",
      "Précision par classe:\n",
      "  Classe 1: 1.0000\n",
      "  Classe 2: 1.0000\n",
      "  Classe 3: 0.9444\n",
      "\n",
      "Rappel par classe:\n",
      "  Classe 1: 1.0000\n",
      "  Classe 2: 0.9412\n",
      "  Classe 3: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(3,), max_iter=1000, random_state=42,  alpha=0.001)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "\n",
    "display_metrics(y_test, y_pred_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f06c7",
   "metadata": {},
   "source": [
    "Version normalisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5b6987fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice de confusion:\n",
      "[[16  0  0]\n",
      " [ 1 15  1]\n",
      " [ 0  3 14]]\n",
      "\n",
      "Accuracy globale: 0.9000\n",
      "\n",
      "Précision par classe:\n",
      "  Classe 1: 0.9412\n",
      "  Classe 2: 0.8333\n",
      "  Classe 3: 0.9333\n",
      "\n",
      "Rappel par classe:\n",
      "  Classe 1: 1.0000\n",
      "  Classe 2: 0.8824\n",
      "  Classe 3: 0.8235\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred_mlp_scaled = mlp.predict(X_test_scaled)\n",
    "\n",
    "display_metrics(y_test, y_pred_mlp_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e4b026",
   "metadata": {},
   "source": [
    "## Application à tous les datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bff42a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (150, 4)\n",
      "y shape: (150,)\n",
      "\n",
      "Perceptron:\n",
      "Matrice de confusion:\n",
      "[[15  1  0]\n",
      " [ 5  7  5]\n",
      " [ 0  2 15]]\n",
      "\n",
      "Accuracy globale: 0.7400\n",
      "\n",
      "Précision par classe:\n",
      "  Classe 1: 0.7500\n",
      "  Classe 2: 0.7000\n",
      "  Classe 3: 0.7500\n",
      "\n",
      "Rappel par classe:\n",
      "  Classe 1: 0.9375\n",
      "  Classe 2: 0.4118\n",
      "  Classe 3: 0.8824\n",
      "\n",
      "Perceptron Multi-Couche:\n",
      "Matrice de confusion:\n",
      "[[16  0  0]\n",
      " [ 1 15  1]\n",
      " [ 0  3 14]]\n",
      "\n",
      "Accuracy globale: 0.9000\n",
      "\n",
      "Précision par classe:\n",
      "  Classe 1: 0.9412\n",
      "  Classe 2: 0.8333\n",
      "  Classe 3: 0.9333\n",
      "\n",
      "Rappel par classe:\n",
      "  Classe 1: 1.0000\n",
      "  Classe 2: 0.8824\n",
      "  Classe 3: 0.8235\n"
     ]
    }
   ],
   "source": [
    "def pipeline(path, seed=42):\n",
    "    X, y = load_data(path)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=seed, stratify=y)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Multi classe\n",
    "    perceptron = Perceptron(max_iter=1000, eta0=0.1, random_state=seed)\n",
    "    perceptron.fit(X_train_scaled, y_train)\n",
    "    y_pred = perceptron.predict(X_test_scaled)\n",
    "    print(\"\\nPerceptron:\")\n",
    "    display_metrics(y_test, y_pred)\n",
    "    \n",
    "    # Multi couche\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(3,), max_iter=1000, random_state=seed,  alpha=0.001)\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "    y_pred = mlp.predict(X_test_scaled)\n",
    "    print(\"\\nPerceptron Multi-Couche:\")  \n",
    "    display_metrics(y_test, y_pred)\n",
    "\n",
    "pipeline('iris.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpdeeprl2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
